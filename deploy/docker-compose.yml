version: "3.7"

services:

  ui_superset:
    image: superset_3.1.2:v2
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ui_superset
    env_file: .env
    restart: unless-stopped
    hostname: superset
    environment:
      - TZ=Europe/Moscow
    ports:
      - 8088:8088
    volumes:
      - ./config.py:/app/superset/config.py
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8088"]
      interval: 10s
      timeout: 10s
      retries: 5
    depends_on:
      - ui_superset_redict
    networks:
      ss:
        ipv4_address: 192.168.28.2

  ui_superset_celery:
    image: superset_3.1.2:v2
    container_name: ui_superset_celery
    env_file: .env
    restart: unless-stopped
    environment:
      - TZ=Europe/Moscow
    volumes:
      - ./config.py:/app/superset/config.py
    command: celery -A superset.tasks.celery_app:app worker -E --pool=prefork -O fair -c 4 -l INFO
    healthcheck:
      test: ["CMD-SHELL", "celery -A superset.tasks.celery_app:app inspect ping -d celery@$$HOSTNAME"]
      interval: 10s
      timeout: 10s
      retries: 5
    depends_on:
      - ui_superset_redict
      - ui_superset
    networks:
      ss:
        ipv4_address: 192.168.28.4

  ui_superset_beat:
    image: superset_3.1.2:v2
    container_name: ui_superset_beat
    env_file: .env
    restart: unless-stopped
    environment:
      - TZ=Europe/Moscow
    volumes:
      - ./config.py:/app/superset/config.py
    command: celery -A superset.tasks.celery_app:app beat --pidfile= -f /tmp/celery_beat.log -s /tmp/celerybeat-schedule
    depends_on:
      - ui_superset_redict
      - ui_superset
    healthcheck:
      disable: true
    networks:
      ss:
        ipv4_address: 192.168.28.5

  ui_superset_flower:
    image: superset_3.1.2:v2
    container_name: ui_superset_flower
    env_file: .env
    restart: unless-stopped
    environment:
      - TZ=Europe/Moscow
    ports:
      - 5555:5555
    volumes:
      - ./config.py:/app/superset/config.py
    command: celery -A superset.tasks.celery_app:app flower
    depends_on:
      - ui_superset_redict
      - ui_superset
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:5555"]
      interval: 10s
      timeout: 10s
      retries: 5
    networks:
      ss:
        ipv4_address: 192.168.28.6
        
  ui_superset_redict:
    image: registry.redict.io/redict:7.3.0-alpine3.19
    container_name: ui_superset_redict
    restart: unless-stopped
    hostname: redict
    ports:
      - 6379:6379
    volumes:
      - ./redict.conf:/redict.conf
    healthcheck:
      test: ["CMD", "redict-cli", "ping"]
      interval: 5s
      timeout: 30s
      retries: 50
    networks:
      ss:
        ipv4_address: 192.168.28.7

  db_superset:
    image: postgres:15.7-alpine3.19
    container_name: db_superset
    shm_size: '2gb'
    restart: always
    env_file: .env
    environment:
      - POSTGRES_DB=$DATABASE_DB
      - POSTGRES_USER=$DATABASE_USER
      - POSTGRES_PASSWORD=$DATABASE_PASSWORD
      - PGDATA=$PGDATA
    ports:
      - "5446:5432"
    volumes:
      - /dev/urandom:/dev/random   # Required to get non-blocking entropy source
      - ./pgdata:/var/lib/postgresql/data/pgdata
#      - ./docker-entrypoint-initdb.d:/docker-entrypoint-initdb.d
    command: >
     postgres
       -c max_connections=500
       -c superuser_reserved_connections=3
       -c shared_buffers=4GB
       -c work_mem=32MB
       -c maintenance_work_mem=320MB
       -c huge_pages=off
       -c random_page_cost=1.25
       -c effective_cache_size=11GB
       -c effective_io_concurrency=100
       -c log_destination=stderr
       -c logging_collector=on
       -c log_filename='postgresql-%G-%m.log'
       -c log_truncate_on_rotation=off
       -c log_rotation_age=10d
       -c client_min_messages=warning
       -c log_min_messages=warning
       -c log_min_error_statement=error
       -c log_line_prefix='%t %u@%r:%d [%p] '
       -c log_min_duration_statement=200ms
       -c log_timezone='Europe/Moscow'
       -c temp_file_limit=10GB
       -c idle_in_transaction_session_timeout=30s
       -c lock_timeout=0
       -c statement_timeout=6000s
       -c shared_preload_libraries=pg_stat_statements
       -c pg_stat_statements.max=10000
       -c pg_stat_statements.track=all
       -c timezone='Europe/Moscow'
       -c track_counts=on
       -c autovacuum=on
       -c track_activities=on
       -c track_io_timing=on
       -c track_functions=pl
       -c max_worker_processes=8
       -c max_parallel_workers_per_gather=4
       -c max_parallel_maintenance_workers=4
       -c max_parallel_workers=8
       -c parallel_leader_participation=on
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "ss"]
      interval: 5s
      retries: 5
    deploy:
      restart_policy:
        condition: on-failure
        delay: 8s
        max_attempts: 5
      resources:
        limits:
          cpus: '4'
    networks:
      ss:
        ipv4_address: 192.168.28.3

networks:
  ss:
    driver: bridge
    ipam:
      config:
        - subnet: 192.168.28.0/24
